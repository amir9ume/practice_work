{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk; nltk.download('stopwords')\n",
    "from nltk.util import ngrams\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from itertools import chain\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "stop_words= stopwords.words('english')\n",
    "stop_words.extend(['from','subject','re','edu','use'])\n",
    "\n",
    "from gensim.test.utils import datapath\n",
    "import utilities\n",
    "\n",
    "\n",
    "#gensim \n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "#spacy for lemmatisation\n",
    "import spacy\n",
    "#plot tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "        for sentence in sentences:\n",
    "            yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts] \n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN','ADJ','VERB','ADV']):\n",
    "    texts_out= []\n",
    "    for sent in texts:\n",
    "        doc= nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags]) \n",
    "    return texts_out\n",
    "\n",
    "def cosine_similiarity(v1,v2):\n",
    "        m1= np.linalg.norm(v1)\n",
    "        m2= np.linalg.norm(v2)\n",
    "        m= m1*m2\n",
    "        d= np.dot(v1,v2)\n",
    "        return d/(m)\n",
    "\n",
    "\n",
    "#stores bag of words for comaprison\n",
    "corpus_vectors=[]\n",
    "v=[]\n",
    "\n",
    "#list_files= sorted(os.listdir('../submitted_papers/'))\n",
    "document_vectors=[]\n",
    "row_lists=[]\n",
    "load_dir=\"../neurips19/submitted_papers/\"\n",
    "data = []\n",
    "doc_names = []   \n",
    "token_len = 256\n",
    "\n",
    "c=0\n",
    "files_read=[]\n",
    "\n",
    "#load data\n",
    "base_folder='./data_info/loaded_pickles_nips19/'    \n",
    "submitted_papers={}\n",
    "with open(base_folder+'big_lemma_data_paper_submitted_nips19.pickle','rb' ) as ll:\n",
    "    submitted_papers=pickle.load(ll)\n",
    "\n",
    "data_submitted_papers=[]\n",
    "\n",
    "for pid in submitted_papers:\n",
    "    src= submitted_papers[pid]#['text']\n",
    "    data_submitted_papers.append(src)\n",
    "\n",
    "#prepare corpus for lda\n",
    "corp=[]\n",
    "for paper in data_submitted_papers:\n",
    "    x= [p.split(' ') for p in paper]\n",
    "    corp.append(x)\n",
    "corp=[j for sub in corp for j in sub]\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "\n",
    "id2word = corpora.Dictionary(corp)\n",
    "id2word.filter_extremes(no_below=2, no_above=0.7)\n",
    "corpus = [id2word.doc2bow(doc) for doc in corp] \n",
    "lda_model= gensim.models.ldamodel.LdaModel(corpus= corpus,  num_topics=25, random_state=100, update_every=1 , chunksize=100,passes=10, alpha='auto', per_word_topics= True)\n",
    "\n",
    "pprint(lda_model.print_topics(num_topics=-1,num_words=12))\n",
    "\n",
    "\n",
    "lda_model.save('./nips19_vectors2/model_lda_nips19')\n",
    "id2word.save_as_text(\"./nips19_vectors2/wordlist_nips19_lda\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
